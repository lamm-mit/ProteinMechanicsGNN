{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RCN1yW6HklZc"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import ModuleList, Embedding\n",
    "from torch.nn import Sequential, ReLU, Linear\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.nn import PNAConv, BatchNorm, global_add_pool\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0AhkVuhMklZg"
   },
   "outputs": [],
   "source": [
    "test_domains = ['1qlc', '2dfe', '2fbo', '2hoa', '4azq', '4id7']\n",
    "\n",
    "dist_th = 12.0  # threshold distance between CA atoms below which edges will be built\n",
    "idx_mode = 63  # first mode = 0, 64th mode = 63\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 50\n",
    "\n",
    "num_layers = 4\n",
    "\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "task_name_temp = 'all_th'+str(int(dist_th))\n",
    "task_name = task_name_temp+'_mode'+str(idx_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LKUbhWcuklZh"
   },
   "outputs": [],
   "source": [
    "checkpoint = torch.load('data/'+task_name+'_Nlayer'+str(num_layers)+\n",
    "                        '_checkpoint'+str(epochs)+'.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LlibewbGklZj"
   },
   "outputs": [],
   "source": [
    "def load_vocab(filename):\n",
    "    try:\n",
    "        d = dict()\n",
    "        with open(filename) as f:\n",
    "            for idx, word in enumerate(f):\n",
    "                word = word.strip()\n",
    "                d[word] = idx\n",
    "\n",
    "    except IOError:\n",
    "        raise MyIOError(filename)\n",
    "    return d\n",
    "\n",
    "vocab_chars = load_vocab(\"food_chars.txt\")\n",
    "\n",
    "\n",
    "def get_node_features(sequence):\n",
    "    seq = []\n",
    "    for res in list(sequence):\n",
    "        seq.append(vocab_chars[res])\n",
    "    \n",
    "    node_features = torch.tensor(seq, dtype=torch.long)\n",
    "    \n",
    "    return node_features\n",
    "\n",
    "\n",
    "def domain2graph(domain):\n",
    "    # load distance matrix\n",
    "    with open('data/'+domain+'_dist.pickle', 'rb') as handle:\n",
    "        protein_dict = pickle.load(handle)\n",
    "\n",
    "    assert domain == protein_dict['domain']\n",
    "    dist = protein_dict['dist']\n",
    "    \n",
    "    # load sequence\n",
    "    f1 = open('data/'+domain+'.fasta', 'r')\n",
    "    first_line = True\n",
    "    for line in f1:\n",
    "        if first_line:\n",
    "            first_line = False\n",
    "        else:\n",
    "            sequence = line[:-1]\n",
    "    f1.close()\n",
    "    node_features = get_node_features(sequence)\n",
    "    \n",
    "    edges = []\n",
    "    CA_distances = []\n",
    "    for idx1 in range(len(sequence)):\n",
    "        for idx2 in range(len(sequence)):\n",
    "            if idx1 != idx2:\n",
    "                distance = dist[idx1][idx2]\n",
    "                if distance < dist_th:\n",
    "                    edges.append([idx1, idx2])\n",
    "                    CA_distances.append(distance)\n",
    "    \n",
    "    edge_index = torch.tensor(edges, dtype=torch.long)\n",
    "    edge_attr = torch.tensor(CA_distances, dtype=torch.float)\n",
    "    \n",
    "    return node_features, edge_index.T, edge_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RpZ8H7_xklZj"
   },
   "outputs": [],
   "source": [
    "test_dataset = []\n",
    "for domain in test_domains:\n",
    "    node_features, edge_index, edge_attr = domain2graph(domain)\n",
    "    data = Data(edge_attr=edge_attr, edge_index=edge_index, x=node_features, y=torch.tensor([-1], dtype=torch.float))\n",
    "    test_dataset.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zem0W6OnklZk"
   },
   "outputs": [],
   "source": [
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VfQ-NaNUklZk"
   },
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.node_emb = Embedding(20, 75)\n",
    "\n",
    "        aggregators = ['mean', 'std']\n",
    "        scalers = ['identity', 'amplification', 'attenuation']\n",
    "\n",
    "        self.convs = ModuleList()\n",
    "        self.batch_norms = ModuleList()\n",
    "        for _ in range(num_layers):\n",
    "            conv = PNAConv(in_channels=75, out_channels=75,\n",
    "                           aggregators=aggregators, scalers=scalers, deg=deg,\n",
    "                           edge_dim=1, towers=5, pre_layers=1, post_layers=1,\n",
    "                           divide_input=False)\n",
    "            self.convs.append(conv)\n",
    "            self.batch_norms.append(BatchNorm(75))\n",
    "\n",
    "        self.mlp = Sequential(Linear(75, 50), ReLU(), Linear(50, 25), ReLU(),\n",
    "                              Linear(25, 1))\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, batch):\n",
    "        x = self.node_emb(x.squeeze())\n",
    "\n",
    "        for conv, batch_norm in zip(self.convs, self.batch_norms):\n",
    "            x = F.relu(batch_norm(conv(x, edge_index, edge_attr.unsqueeze(1))))\n",
    "\n",
    "        x = global_add_pool(x, batch)\n",
    "        return self.mlp(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V-yqs1kfklZl"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "deg = checkpoint['deg']\n",
    "model = Net().to(device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DaMjuQyAklZm"
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def get_test_results(loader):\n",
    "    pred = []\n",
    "    truth = []\n",
    "    model.eval()\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        out = model(data.x, data.edge_index, data.edge_attr, data.batch)\n",
    "        pred += out.squeeze().tolist()\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y1t0MvrCklZn"
   },
   "outputs": [],
   "source": [
    "pred = get_test_results(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0VVPoT2OklZn"
   },
   "outputs": [],
   "source": [
    "print('Domain    ML freq (cm-1)')\n",
    "for domain, f_ML in zip(test_domains, pred):\n",
    "    print(domain, f_ML)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "inference_new-test-seq.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
